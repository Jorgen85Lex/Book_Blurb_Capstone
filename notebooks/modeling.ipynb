{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23816ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lexil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lexil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508a0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text_description):\n",
    "    text_description = text_description.lower()\n",
    "    text_description = text_description.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text_description)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd53ee53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genre</th>\n",
       "      <th>published_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>processed_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the silver chair</td>\n",
       "      <td>two english children undergo hairraising adven...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>1998</td>\n",
       "      <td>clive staples lewis</td>\n",
       "      <td>two english child undergo hairraising adventur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a game of thrones</td>\n",
       "      <td>fantasyroman</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2011</td>\n",
       "      <td>george r r martin</td>\n",
       "      <td>fantasyroman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fablehaven</td>\n",
       "      <td>when kendra and seth go to stay at their grand...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2007</td>\n",
       "      <td>brandon mull</td>\n",
       "      <td>kendra seth go stay grandparent estate discove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a wizard of earthsea</td>\n",
       "      <td>originally published in 1968 ursula k le guins...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2012</td>\n",
       "      <td>ursula k le guin</td>\n",
       "      <td>originally published 1968 ursula k le guins wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lodestar</td>\n",
       "      <td>betrayed by one of their closest allies sophie...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2017</td>\n",
       "      <td>shannon messenger</td>\n",
       "      <td>betrayed one closest ally sophies whole world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>out of the everywhere</td>\n",
       "      <td>topics include astronomy humanity radiation ma...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>1990</td>\n",
       "      <td>isaac asimov</td>\n",
       "      <td>topic include astronomy humanity radiation mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>quantum shorts</td>\n",
       "      <td>this book presents winning and shortlisted sto...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2019</td>\n",
       "      <td>michael brooks jenny hogan puah xin yi</td>\n",
       "      <td>book present winning shortlisted story past ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>novel science</td>\n",
       "      <td>novel science is the first indepth study of th...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2013</td>\n",
       "      <td>adelene buckland</td>\n",
       "      <td>novel science first indepth study shocking gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>fantastic voyages</td>\n",
       "      <td>by revealing the facts behind the fiction of s...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2006</td>\n",
       "      <td>leroy w dubeck suzanne e moshier judith e boss</td>\n",
       "      <td>revealing fact behind fiction finest film scif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>holy scifi</td>\n",
       "      <td>can a computer have a soul are religion and sc...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2014</td>\n",
       "      <td>paul j nahin</td>\n",
       "      <td>computer soul religion science mutually exclus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "0         the silver chair  two english children undergo hairraising adven...   \n",
       "1        a game of thrones                                       fantasyroman   \n",
       "2               fablehaven  when kendra and seth go to stay at their grand...   \n",
       "3     a wizard of earthsea  originally published in 1968 ursula k le guins...   \n",
       "4                 lodestar  betrayed by one of their closest allies sophie...   \n",
       "..                     ...                                                ...   \n",
       "776  out of the everywhere  topics include astronomy humanity radiation ma...   \n",
       "777         quantum shorts  this book presents winning and shortlisted sto...   \n",
       "778          novel science  novel science is the first indepth study of th...   \n",
       "779      fantastic voyages  by revealing the facts behind the fiction of s...   \n",
       "780             holy scifi  can a computer have a soul are religion and sc...   \n",
       "\n",
       "               genre  published_date  \\\n",
       "0            fantasy            1998   \n",
       "1            fantasy            2011   \n",
       "2            fantasy            2007   \n",
       "3            fantasy            2012   \n",
       "4            fantasy            2017   \n",
       "..               ...             ...   \n",
       "776  science fiction            1990   \n",
       "777  science fiction            2019   \n",
       "778  science fiction            2013   \n",
       "779  science fiction            2006   \n",
       "780  science fiction            2014   \n",
       "\n",
       "                                            authors  \\\n",
       "0                               clive staples lewis   \n",
       "1                                 george r r martin   \n",
       "2                                      brandon mull   \n",
       "3                                  ursula k le guin   \n",
       "4                                 shannon messenger   \n",
       "..                                              ...   \n",
       "776                                    isaac asimov   \n",
       "777          michael brooks jenny hogan puah xin yi   \n",
       "778                                adelene buckland   \n",
       "779  leroy w dubeck suzanne e moshier judith e boss   \n",
       "780                                    paul j nahin   \n",
       "\n",
       "                                 processed_description  \n",
       "0    two english child undergo hairraising adventur...  \n",
       "1                                         fantasyroman  \n",
       "2    kendra seth go stay grandparent estate discove...  \n",
       "3    originally published 1968 ursula k le guins wi...  \n",
       "4    betrayed one closest ally sophies whole world ...  \n",
       "..                                                 ...  \n",
       "776  topic include astronomy humanity radiation mag...  \n",
       "777  book present winning shortlisted story past ed...  \n",
       "778  novel science first indepth study shocking gro...  \n",
       "779  revealing fact behind fiction finest film scif...  \n",
       "780  computer soul religion science mutually exclus...  \n",
       "\n",
       "[781 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbooksprocessed = pd.read_csv('../data/allbooksprocessed.csv')\n",
    "allbooksprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3c60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = allbooksprocessed['processed_description']\n",
    "y = allbooksprocessed['genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2def4b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Count Summary:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           fantasy       0.55      0.63      0.59        27\n",
      "historical fiction       0.64      0.36      0.46        25\n",
      "           mystery       0.70      0.64      0.67        33\n",
      "           romance       0.57      0.70      0.63        37\n",
      "   science fiction       0.78      0.80      0.79        35\n",
      "\n",
      "          accuracy                           0.64       157\n",
      "         macro avg       0.65      0.63      0.63       157\n",
      "      weighted avg       0.65      0.64      0.64       157\n",
      "\n",
      "Accuracy: 0.643312101910828\n",
      "Confusion Matrix:\n",
      " [[17  3  1  5  1]\n",
      " [ 5  9  2  6  3]\n",
      " [ 2  0 21  6  4]\n",
      " [ 4  2  5 26  0]\n",
      " [ 3  0  1  3 28]]\n",
      "Bigram Count Summary:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           fantasy       0.41      0.33      0.37        27\n",
      "historical fiction       0.50      0.04      0.07        25\n",
      "           mystery       0.28      0.70      0.40        33\n",
      "           romance       0.46      0.43      0.44        37\n",
      "   science fiction       0.94      0.46      0.62        35\n",
      "\n",
      "          accuracy                           0.41       157\n",
      "         macro avg       0.52      0.39      0.38       157\n",
      "      weighted avg       0.53      0.41      0.40       157\n",
      "\n",
      "Accuracy: 0.4140127388535032\n",
      "Confusion Matrix:\n",
      " [[ 9  0 14  3  1]\n",
      " [ 2  1 14  8  0]\n",
      " [ 3  0 23  7  0]\n",
      " [ 3  1 17 16  0]\n",
      " [ 5  0 13  1 16]]\n"
     ]
    }
   ],
   "source": [
    "unigram_count_vectorizer = CountVectorizer()\n",
    "unigram_model = make_pipeline(unigram_count_vectorizer, LogisticRegression(max_iter=1000))\n",
    "unigram_model.fit(X_train, y_train)\n",
    "y_pred_uni = unigram_model.predict(X_test)\n",
    "print(\"Unigram Count Summary:\\n\", classification_report(y_test, y_pred_uni))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_uni)}')\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_uni))\n",
    "\n",
    "bigram_count_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "bigram_model = make_pipeline(bigram_count_vectorizer, LogisticRegression(max_iter=1000))\n",
    "bigram_model.fit(X_train, y_train)\n",
    "y_pred_bi = bigram_model.predict(X_test)\n",
    "print(\"Bigram Count Summary:\\n\", classification_report(y_test, y_pred_bi))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_bi)}')\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba12a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Best parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 500}\n",
      "Best cross-validation accuracy: 0.6521806451612903\n",
      "Test set classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           fantasy       0.57      0.63      0.60        27\n",
      "historical fiction       0.73      0.32      0.44        25\n",
      "           mystery       0.68      0.70      0.69        33\n",
      "           romance       0.54      0.73      0.62        37\n",
      "   science fiction       0.88      0.80      0.84        35\n",
      "\n",
      "          accuracy                           0.66       157\n",
      "         macro avg       0.68      0.64      0.64       157\n",
      "      weighted avg       0.68      0.66      0.65       157\n",
      "\n",
      "Test set accuracy: 0.6560509554140127\n",
      "Test set confusion matrix:\n",
      " [[17  2  1  6  1]\n",
      " [ 4  8  3  9  1]\n",
      " [ 2  0 23  6  2]\n",
      " [ 3  1  6 27  0]\n",
      " [ 4  0  1  2 28]]\n"
     ]
    }
   ],
   "source": [
    "count_pipeline = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1, 2)),  # unigrams and bigrams for count vect\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__max_iter': [500, 1000, 1500]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(count_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_count_pipeline = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Test set classification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Test set accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Test set confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302e7385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features for class 'fantasy':\n",
      "  adventure: 0.3813\n",
      "  world: 0.2247\n",
      "  prince: 0.1969\n",
      "  magical: 0.1843\n",
      "  edition: 0.1827\n",
      "  wizard: 0.1801\n",
      "  moomins: 0.1661\n",
      "  oz: 0.1615\n",
      "  six: 0.1608\n",
      "  evil: 0.1502\n",
      "\n",
      "Top features for class 'historical fiction':\n",
      "  war: 0.2825\n",
      "  young: 0.2186\n",
      "  life: 0.2179\n",
      "  soon: 0.1902\n",
      "  author: 0.1870\n",
      "  london: 0.1841\n",
      "  love: 0.1837\n",
      "  family: 0.1704\n",
      "  tribe: 0.1575\n",
      "  marriage: 0.1397\n",
      "\n",
      "Top features for class 'mystery':\n",
      "  murder: 0.5240\n",
      "  mystery: 0.3848\n",
      "  death: 0.2427\n",
      "  wife: 0.2132\n",
      "  killer: 0.2107\n",
      "  old: 0.1992\n",
      "  nancy: 0.1942\n",
      "  marple: 0.1811\n",
      "  miss: 0.1770\n",
      "  crime: 0.1726\n",
      "\n",
      "Top features for class 'romance':\n",
      "  love: 0.4142\n",
      "  heart: 0.2794\n",
      "  bestselling: 0.2039\n",
      "  text: 0.1806\n",
      "  relationship: 0.1679\n",
      "  romantic: 0.1549\n",
      "  mother: 0.1533\n",
      "  price: 0.1518\n",
      "  time bestselling: 0.1516\n",
      "  sister: 0.1458\n",
      "\n",
      "Top features for class 'science fiction':\n",
      "  fiction: 0.6083\n",
      "  science: 0.5391\n",
      "  work: 0.2735\n",
      "  book: 0.2320\n",
      "  study: 0.2126\n",
      "  literary: 0.2100\n",
      "  future: 0.2082\n",
      "  explores: 0.1962\n",
      "  writer: 0.1856\n",
      "  include: 0.1801\n"
     ]
    }
   ],
   "source": [
    "vectorizer = best_count_pipeline.named_steps['countvectorizer']\n",
    "classifier = best_count_pipeline.named_steps['logisticregression']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "num_top_features = 10  \n",
    "class_labels = classifier.classes_\n",
    "\n",
    "for i, class_label in enumerate(class_labels):\n",
    "    coefs = classifier.coef_[i]\n",
    "    top_indices = np.argsort(coefs)[-num_top_features:]\n",
    "    print(f\"\\nTop features for class '{class_label}':\")\n",
    "    for idx in reversed(top_indices):\n",
    "        print(f\"  {feature_names[idx]}: {coefs[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62371e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram TFIDF Summary:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           fantasy       0.84      0.59      0.70        27\n",
      "historical fiction       0.67      0.16      0.26        25\n",
      "           mystery       0.68      0.70      0.69        33\n",
      "           romance       0.50      0.81      0.62        37\n",
      "   science fiction       0.84      0.91      0.88        35\n",
      "\n",
      "          accuracy                           0.67       157\n",
      "         macro avg       0.71      0.63      0.63       157\n",
      "      weighted avg       0.70      0.67      0.65       157\n",
      "\n",
      "Accuracy: 0.6687898089171974\n",
      "Confusion Matrix:\n",
      " [[16  1  1  8  1]\n",
      " [ 2  4  3 15  1]\n",
      " [ 0  0 23  6  4]\n",
      " [ 0  1  6 30  0]\n",
      " [ 1  0  1  1 32]]\n",
      "Bigram TFIDF Summary:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           fantasy       0.80      0.15      0.25        27\n",
      "historical fiction       0.50      0.04      0.07        25\n",
      "           mystery       0.60      0.27      0.38        33\n",
      "           romance       0.35      0.95      0.51        37\n",
      "   science fiction       0.78      0.80      0.79        35\n",
      "\n",
      "          accuracy                           0.49       157\n",
      "         macro avg       0.61      0.44      0.40       157\n",
      "      weighted avg       0.60      0.49      0.43       157\n",
      "\n",
      "Accuracy: 0.49044585987261147\n",
      "Confusion Matrix:\n",
      " [[ 4  0  2 16  5]\n",
      " [ 0  1  2 21  1]\n",
      " [ 0  0  9 22  2]\n",
      " [ 0  1  1 35  0]\n",
      " [ 1  0  1  5 28]]\n"
     ]
    }
   ],
   "source": [
    "unigram_tfidf_vectorizer = TfidfVectorizer()\n",
    "unigram_model = make_pipeline(unigram_tfidf_vectorizer, LogisticRegression(max_iter=1000))\n",
    "unigram_model.fit(X_train, y_train)\n",
    "y_pred_uni = unigram_model.predict(X_test)\n",
    "print(\"Unigram TFIDF Summary:\\n\", classification_report(y_test, y_pred_uni))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_uni)}')\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_uni))\n",
    "\n",
    "bigram_tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 2))\n",
    "bigram_model = make_pipeline(bigram_tfidf_vectorizer, LogisticRegression(max_iter=1000))\n",
    "bigram_model.fit(X_train, y_train)\n",
    "y_pred_bi = bigram_model.predict(X_test)\n",
    "print(\"Bigram TFIDF Summary:\\n\", classification_report(y_test, y_pred_bi))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_bi)}')\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17617ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Best parameters: {'logisticregression__C': 10, 'logisticregression__max_iter': 500}\n",
      "Best cross-validation accuracy: 0.6939096774193547\n",
      "Test set classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           fantasy       0.77      0.63      0.69        27\n",
      "historical fiction       0.68      0.52      0.59        25\n",
      "           mystery       0.72      0.70      0.71        33\n",
      "           romance       0.60      0.73      0.66        37\n",
      "   science fiction       0.82      0.91      0.86        35\n",
      "\n",
      "          accuracy                           0.71       157\n",
      "         macro avg       0.72      0.70      0.70       157\n",
      "      weighted avg       0.72      0.71      0.71       157\n",
      "\n",
      "Test set accuracy: 0.7133757961783439\n",
      "Test set confusion matrix:\n",
      " [[17  3  1  5  1]\n",
      " [ 2 13  2  6  2]\n",
      " [ 0  0 23  6  4]\n",
      " [ 2  3  5 27  0]\n",
      " [ 1  0  1  1 32]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1, 2)),  # unigrams and bigrams for tfidf\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__max_iter': [500, 1000, 1500]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(tfidf_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_count_pipeline = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Test set classification report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Test set accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Test set confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f68e95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features for class 'fantasy':\n",
      "  adventure: 3.0033\n",
      "  oz: 1.9245\n",
      "  wizard: 1.8062\n",
      "  eighteen science: 1.7420\n",
      "  prince: 1.7226\n",
      "  magical: 1.6951\n",
      "  moomins: 1.6166\n",
      "  eighteen: 1.6002\n",
      "  publisher description: 1.5910\n",
      "  edition: 1.5572\n",
      "\n",
      "Top features for class 'historical fiction':\n",
      "  war: 2.2590\n",
      "  family: 1.6721\n",
      "  life: 1.6308\n",
      "  young: 1.4651\n",
      "  london: 1.4537\n",
      "  woman: 1.3761\n",
      "  love: 1.3640\n",
      "  tribe: 1.2780\n",
      "  author: 1.2405\n",
      "  make: 1.1650\n",
      "\n",
      "Top features for class 'mystery':\n",
      "  murder: 3.8512\n",
      "  mystery: 2.7435\n",
      "  fantasyroman: 2.4254\n",
      "  death: 1.8694\n",
      "  killer: 1.7524\n",
      "  marple: 1.6772\n",
      "  nancy: 1.5984\n",
      "  book: 1.5567\n",
      "  wife: 1.4905\n",
      "  miss marple: 1.4818\n",
      "\n",
      "Top features for class 'romance':\n",
      "  love: 3.1383\n",
      "  heart: 2.0364\n",
      "  bestselling: 1.5710\n",
      "  romantic: 1.5150\n",
      "  shes: 1.3683\n",
      "  time bestselling: 1.3146\n",
      "  sister: 1.2902\n",
      "  bestselling author: 1.2578\n",
      "  york time: 1.2398\n",
      "  beach: 1.2282\n",
      "\n",
      "Top features for class 'science fiction':\n",
      "  science: 5.4166\n",
      "  fiction: 5.1131\n",
      "  future: 2.0265\n",
      "  work: 1.9857\n",
      "  study: 1.9170\n",
      "  literary: 1.9108\n",
      "  science fiction: 1.7448\n",
      "  space: 1.7443\n",
      "  explores: 1.6836\n",
      "  form: 1.6777\n"
     ]
    }
   ],
   "source": [
    "vectorizer = best_count_pipeline.named_steps['tfidfvectorizer']\n",
    "classifier = best_count_pipeline.named_steps['logisticregression']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "num_top_features = 10  \n",
    "class_labels = classifier.classes_\n",
    "\n",
    "for i, class_label in enumerate(class_labels):\n",
    "    coefs = classifier.coef_[i]\n",
    "    top_indices = np.argsort(coefs)[-num_top_features:]\n",
    "    print(f\"\\nTop features for class '{class_label}':\")\n",
    "    for idx in reversed(top_indices):\n",
    "        print(f\"  {feature_names[idx]}: {coefs[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9efd1114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>genre</th>\n",
       "      <th>published_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>processed_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the silver chair</td>\n",
       "      <td>two english children undergo hairraising adven...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>1998</td>\n",
       "      <td>clive staples lewis</td>\n",
       "      <td>two english child undergo hairraising adventur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a game of thrones</td>\n",
       "      <td>fantasyroman</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2011</td>\n",
       "      <td>george r r martin</td>\n",
       "      <td>fantasyroman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fablehaven</td>\n",
       "      <td>when kendra and seth go to stay at their grand...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2007</td>\n",
       "      <td>brandon mull</td>\n",
       "      <td>kendra seth go stay grandparent estate discove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a wizard of earthsea</td>\n",
       "      <td>originally published in 1968 ursula k le guins...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2012</td>\n",
       "      <td>ursula k le guin</td>\n",
       "      <td>originally published 1968 ursula k le guins wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lodestar</td>\n",
       "      <td>betrayed by one of their closest allies sophie...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>2017</td>\n",
       "      <td>shannon messenger</td>\n",
       "      <td>betrayed one closest ally sophies whole world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>out of the everywhere</td>\n",
       "      <td>topics include astronomy humanity radiation ma...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>1990</td>\n",
       "      <td>isaac asimov</td>\n",
       "      <td>topic include astronomy humanity radiation mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>quantum shorts</td>\n",
       "      <td>this book presents winning and shortlisted sto...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2019</td>\n",
       "      <td>michael brooks jenny hogan puah xin yi</td>\n",
       "      <td>book present winning shortlisted story past ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>novel science</td>\n",
       "      <td>novel science is the first indepth study of th...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2013</td>\n",
       "      <td>adelene buckland</td>\n",
       "      <td>novel science first indepth study shocking gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>fantastic voyages</td>\n",
       "      <td>by revealing the facts behind the fiction of s...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2006</td>\n",
       "      <td>leroy w dubeck suzanne e moshier judith e boss</td>\n",
       "      <td>revealing fact behind fiction finest film scif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>holy scifi</td>\n",
       "      <td>can a computer have a soul are religion and sc...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>2014</td>\n",
       "      <td>paul j nahin</td>\n",
       "      <td>computer soul religion science mutually exclus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "0         the silver chair  two english children undergo hairraising adven...   \n",
       "1        a game of thrones                                       fantasyroman   \n",
       "2               fablehaven  when kendra and seth go to stay at their grand...   \n",
       "3     a wizard of earthsea  originally published in 1968 ursula k le guins...   \n",
       "4                 lodestar  betrayed by one of their closest allies sophie...   \n",
       "..                     ...                                                ...   \n",
       "776  out of the everywhere  topics include astronomy humanity radiation ma...   \n",
       "777         quantum shorts  this book presents winning and shortlisted sto...   \n",
       "778          novel science  novel science is the first indepth study of th...   \n",
       "779      fantastic voyages  by revealing the facts behind the fiction of s...   \n",
       "780             holy scifi  can a computer have a soul are religion and sc...   \n",
       "\n",
       "               genre  published_date  \\\n",
       "0            fantasy            1998   \n",
       "1            fantasy            2011   \n",
       "2            fantasy            2007   \n",
       "3            fantasy            2012   \n",
       "4            fantasy            2017   \n",
       "..               ...             ...   \n",
       "776  science fiction            1990   \n",
       "777  science fiction            2019   \n",
       "778  science fiction            2013   \n",
       "779  science fiction            2006   \n",
       "780  science fiction            2014   \n",
       "\n",
       "                                            authors  \\\n",
       "0                               clive staples lewis   \n",
       "1                                 george r r martin   \n",
       "2                                      brandon mull   \n",
       "3                                  ursula k le guin   \n",
       "4                                 shannon messenger   \n",
       "..                                              ...   \n",
       "776                                    isaac asimov   \n",
       "777          michael brooks jenny hogan puah xin yi   \n",
       "778                                adelene buckland   \n",
       "779  leroy w dubeck suzanne e moshier judith e boss   \n",
       "780                                    paul j nahin   \n",
       "\n",
       "                                 processed_description  \n",
       "0    two english child undergo hairraising adventur...  \n",
       "1                                         fantasyroman  \n",
       "2    kendra seth go stay grandparent estate discove...  \n",
       "3    originally published 1968 ursula k le guins wi...  \n",
       "4    betrayed one closest ally sophies whole world ...  \n",
       "..                                                 ...  \n",
       "776  topic include astronomy humanity radiation mag...  \n",
       "777  book present winning shortlisted story past ed...  \n",
       "778  novel science first indepth study shocking gro...  \n",
       "779  revealing fact behind fiction finest film scif...  \n",
       "780  computer soul religion science mutually exclus...  \n",
       "\n",
       "[781 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbooksprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1805aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>published_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the silver chair</td>\n",
       "      <td>two english children undergo hairraising adven...</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>clive staples lewis</td>\n",
       "      <td>two english child undergo hairraising adventur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a game of thrones</td>\n",
       "      <td>fantasyroman</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>george r r martin</td>\n",
       "      <td>fantasyroman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fablehaven</td>\n",
       "      <td>when kendra and seth go to stay at their grand...</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>brandon mull</td>\n",
       "      <td>kendra seth go stay grandparent estate discove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a wizard of earthsea</td>\n",
       "      <td>originally published in 1968 ursula k le guins...</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>ursula k le guin</td>\n",
       "      <td>originally published 1968 ursula k le guins wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lodestar</td>\n",
       "      <td>betrayed by one of their closest allies sophie...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>shannon messenger</td>\n",
       "      <td>betrayed one closest ally sophies whole world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>out of the everywhere</td>\n",
       "      <td>topics include astronomy humanity radiation ma...</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>isaac asimov</td>\n",
       "      <td>topic include astronomy humanity radiation mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>quantum shorts</td>\n",
       "      <td>this book presents winning and shortlisted sto...</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>michael brooks jenny hogan puah xin yi</td>\n",
       "      <td>book present winning shortlisted story past ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>novel science</td>\n",
       "      <td>novel science is the first indepth study of th...</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>adelene buckland</td>\n",
       "      <td>novel science first indepth study shocking gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>fantastic voyages</td>\n",
       "      <td>by revealing the facts behind the fiction of s...</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>leroy w dubeck suzanne e moshier judith e boss</td>\n",
       "      <td>revealing fact behind fiction finest film scif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>holy scifi</td>\n",
       "      <td>can a computer have a soul are religion and sc...</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>paul j nahin</td>\n",
       "      <td>computer soul religion science mutually exclus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                        description  \\\n",
       "0         the silver chair  two english children undergo hairraising adven...   \n",
       "1        a game of thrones                                       fantasyroman   \n",
       "2               fablehaven  when kendra and seth go to stay at their grand...   \n",
       "3     a wizard of earthsea  originally published in 1968 ursula k le guins...   \n",
       "4                 lodestar  betrayed by one of their closest allies sophie...   \n",
       "..                     ...                                                ...   \n",
       "776  out of the everywhere  topics include astronomy humanity radiation ma...   \n",
       "777         quantum shorts  this book presents winning and shortlisted sto...   \n",
       "778          novel science  novel science is the first indepth study of th...   \n",
       "779      fantastic voyages  by revealing the facts behind the fiction of s...   \n",
       "780             holy scifi  can a computer have a soul are religion and sc...   \n",
       "\n",
       "     label  published_date                                         authors  \\\n",
       "0        0            1998                             clive staples lewis   \n",
       "1        0            2011                               george r r martin   \n",
       "2        0            2007                                    brandon mull   \n",
       "3        0            2012                                ursula k le guin   \n",
       "4        0            2017                               shannon messenger   \n",
       "..     ...             ...                                             ...   \n",
       "776      4            1990                                    isaac asimov   \n",
       "777      4            2019          michael brooks jenny hogan puah xin yi   \n",
       "778      4            2013                                adelene buckland   \n",
       "779      4            2006  leroy w dubeck suzanne e moshier judith e boss   \n",
       "780      4            2014                                    paul j nahin   \n",
       "\n",
       "                                                  text  \n",
       "0    two english child undergo hairraising adventur...  \n",
       "1                                         fantasyroman  \n",
       "2    kendra seth go stay grandparent estate discove...  \n",
       "3    originally published 1968 ursula k le guins wi...  \n",
       "4    betrayed one closest ally sophies whole world ...  \n",
       "..                                                 ...  \n",
       "776  topic include astronomy humanity radiation mag...  \n",
       "777  book present winning shortlisted story past ed...  \n",
       "778  novel science first indepth study shocking gro...  \n",
       "779  revealing fact behind fiction finest film scif...  \n",
       "780  computer soul religion science mutually exclus...  \n",
       "\n",
       "[781 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbooksprocessed = allbooksprocessed.rename(columns={\"processed_description\": \"text\", \"genre\": \"label\"})\n",
    "allbooksprocessed['label'] = LabelEncoder().fit_transform(allbooksprocessed['label'])\n",
    "allbooksprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "926d5634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = allbooksprocessed['label'].nunique()\n",
    "num_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52cfaa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(allbooksprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68eac648",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73aff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'description', 'label', 'published_date', 'authors', 'text'],\n",
       "    num_rows: 624\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e757e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0252fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1403805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexil\\anaconda3\\Lib\\site-packages\\datasets\\utils\\_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe264458a924e2dbae7b3beb6b73cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexil\\anaconda3\\Lib\\site-packages\\datasets\\utils\\_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87736946fe814ebab7f59f4152062860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda df: tokenizer(df['text'], padding=\"max_length\", truncation=True), batched=True)\n",
    "test_dataset = test_dataset.map(lambda df: tokenizer(df['text'], padding=\"max_length\", truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97613f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f507b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e04935cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TrainingArguments(num_train_epochs = 5,\n",
    "                            weight_decay = 0.01,\n",
    "                            report_to = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3af7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_object = Trainer(\n",
    "    model = model,\n",
    "    args = training,\n",
    "    train_dataset = train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21065e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexil\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 10/390 00:56 < 44:30, 0.14 it/s, Epoch 0.12/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_object.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = training_object.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = predicted.predictions\n",
    "true_labels = predicted.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc809a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predicted.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set classification report:\\n\", classification_report(true_labels, preds))\n",
    "print(\"Test set accuracy:\", accuracy_score(true_labels, preds))\n",
    "print(\"Test set confusion matrix:\\n\", confusion_matrix(true_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(true_labels, preds))\n",
    "print(classification_report(true_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e9f9c",
   "metadata": {},
   "source": [
    "Fantasy - pretty strong, pretty distinct words. \n",
    "Historical fiction - worst performancce at 52% possible crossover with things like love, war, family  \n",
    "Mystery - good, maybe crossover? (crime/love could be getting things mixed with romance or historical fiction perhaps.)\n",
    "Romance - Good \n",
    "Sci-Fi  - best - likely because the vocabulary is pretty distinct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec673236",
   "metadata": {},
   "source": [
    "Next steps - try getting more books? \n",
    "attempt to look at bi-grams \n",
    "topic modeling --  pi - LDA -vis\n",
    "LoRA ?\n",
    "Jaccard similarity between genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "\n",
    "allbooksprocessed['processed_text'] = allbooksprocessed['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71201258",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = allbooksprocessed['processed_text'].tolist()\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 5 \n",
    "\n",
    "lda_model = LdaMulticore(corpus, num_topics=num_topics, id2word=dictionary, passes=10, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(num_topics):\n",
    "    print(f\"Topic {idx}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d212f63",
   "metadata": {},
   "source": [
    "fantasy\n",
    "historical fiction\n",
    "mystery\n",
    "romance\n",
    "science fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vis.topic_info['Category'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90645249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
